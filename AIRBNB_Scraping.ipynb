{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4 import SoupStrainer\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee92c1af",
   "metadata": {},
   "source": [
    "# Notebook for Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ff440",
   "metadata": {},
   "source": [
    "After having chosen a destination and fixed dates (the short the period is the less you'll have duplicates), get the link of the main page on Airbnb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d940f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for Nice, France :\n",
    "\n",
    "page = \"https://www.airbnb.fr/s/Nice--France/homes?adults=1&refinement_paths%5B%5D=%2Fhomes&checkin=2022-09-12&checkout=2022-09-18&tab_id=home_tab&query=Nice%2C%20France&flexible_trip_lengths%5B%5D=one_week&source=structured_search_input_header&search_type=unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4373c74d",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "The site returned 300 ads (20 ads spread over 15 pages). The following cell allows you to get the links of the 300 ads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65227828",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_links = []\n",
    "pages_link = []\n",
    "hrefs = []\n",
    "links = []\n",
    "\n",
    "# Get the link of the 15 pages of results\n",
    "for y in range(15) :\n",
    "    pages_link.append(page + f'&items_offset={y*20}&section_offset=3')\n",
    "    \n",
    "\n",
    "# Looking for href links in <a> tags.\n",
    "\n",
    "for z in pages_link :\n",
    "    selection = SoupStrainer(\"a\")\n",
    "    b = bs(requests.get(z).content, 'html.parser',parse_only=selection)\n",
    "    href_tags = b.find_all('a',class_=\"ln2bl2p dir dir-ltr\",href=True)\n",
    "    hrefs.append(href_tags)\n",
    "for w in hrefs : \n",
    "    for x in w :\n",
    "        a = x['href']\n",
    "        partial_links.append(a)\n",
    "        \n",
    "        \n",
    "# Reconstruct the full link of each ad\n",
    "for i in partial_links :\n",
    "    v = 'https://www.airbnb.fr'+i\n",
    "    links.append(v) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eace9b",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "Check if you have 300 links. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db352227",
   "metadata": {},
   "source": [
    "In order to avoid driver errors or bugs, it is recommended to scrap the links in groups of 50. 100 if your internet connection is stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3baeb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "list1 = links[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ca9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "list1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f431a74c",
   "metadata": {},
   "source": [
    "If you need to, test the entire code with 2 or 3 links."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf63ca3",
   "metadata": {},
   "source": [
    "<br/>\n",
    "Step 1 : Enter in the dictionary the equipment you want to scrap. <br/>\n",
    "Step 2 : Create a list that contains the equipment that interests you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f84370",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {'link':[],'title':[],'price':[],'superhost':[],'grade':[],'nb_comments':[],'nb_travelers':[],'nb_bedrooms':[],'nb_beds':[],\n",
    "                'nb_bath':[],'city':[],\n",
    "                'Télévision':[],'Chauffage':[],'Lave-vaisselle':[],'Wifi':[],'Climatisation':[],\n",
    "                'Entrée privée':[],'Jacuzzi':[],'Barbecue':[],'Équipements de base':[],'Lave-linge':[],'Four à micro-ondes':[], \n",
    "                'Réfrigérateur':[],'Cuisinière':[],'Cafetière':[],'Séjours longue durée autorisés':[],'Baignoire':[]\n",
    "                ,'Accès plage ou bord de mer':[],'Ascenseur':[],'Arrivée autonome':[],\n",
    "                'Logement de plain-pied':[],'Vue panoramique sur la ville':[],'Vue sur la piscine':[],\n",
    "                'Vue sur la baie':[],'Vue sur le jardin':[],'Vue sur la plage':[],'Vue sur le parc':[],'Vue sur le port':[],\n",
    "                'Vue sur la mer':[],'Vue sur la montagne':[],'Oreillers et couvertures supplémentaires':[],\n",
    "                'Congélateur':[],'Coffre-fort':[],\n",
    "                'Patio ou balcon : privé(e)':[],'Jardin privé(e), Clôture intégrale':[],'Parking gratuit':[],'Piscine':[],\n",
    "                'Salle de sport':[],'Animaux acceptés':[],\"Clés remises par l'hôte\":[] ,'Équipements de cuisine de base':[]}\n",
    "\n",
    "\n",
    "# Adapt the elements to the language of the airbnb site you are using\n",
    "equipment = ['Cuisine','Télévision','Chauffage','Coffre-fort',\n",
    "                'Lave-vaisselle','Wifi','Climatisation','Entrée privée','Jacuzzi','Barbecue','Équipements de base',\n",
    "                'Lave-linge','Four à micro-ondes', 'Arrivée autonome',\n",
    "                'Réfrigérateur','Cafetière','Séjours longue durée autorisés','Baignoire',\n",
    "                'Accès plage ou bord de mer','Ascenseur',\n",
    "                'Logement de plain-pied','Vue panoramique sur la ville','Vue sur la piscine',\n",
    "                'Vue sur la baie','Vue sur le jardin','Vue sur la plage','Vue sur le parc','Vue sur le port',\n",
    "                'Vue sur la mer','Vue sur la montagne','Oreillers et couvertures supplémentaires',\n",
    "                'Congélateur','Patio ou balcon : privé(e)','Jardin privé(e), Clôture intégrale','Parking gratuit','Piscine',\n",
    "                'Salle de sport','Animaux acceptés',\"Clés remises par l'hôte\",'Équipements de cuisine de base']\n",
    "\n",
    "\n",
    "# The time sleeps are necessary: so as not to have your IP address blocked by the site because of the excessive number of requests\n",
    "# for a limited period of time AND because they allow pages to take time to load.\n",
    "\n",
    "\n",
    "for link in list1 :\n",
    "    \n",
    "    # Keep the link of the ad\n",
    "    features_dict['link'].append(link)\n",
    "    \n",
    "    # Opening of the driver : I used a Chrome driver\n",
    "    #driver = webdriver.Chrome(r\"C:\\Users\\sonia\\.anaconda\\navigator\\.anaconda\\navigator\\scripts\\chromedriver.exe\")\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Opening of the ad link in the driver\n",
    "    driver.get(link)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    # Cookie button processing: click 'ok'\n",
    "    driver.find_elements(By.XPATH,\"/html/body/div[5]/div/div/div[1]/div/div/div[3]/section/div[2]/div[2]/button\")[0].click()\n",
    "\n",
    "    \n",
    "    \n",
    "    # Scraping main elements :\n",
    "    \n",
    "    # Title of the ad\n",
    "    title_search = driver.find_elements(By.CLASS_NAME, value=\"_fecoyn4\")\n",
    "    for elem in title_search : \n",
    "        features_dict['title'].append(elem.text)\n",
    "\n",
    "    # Price per night\n",
    "    prix_search = driver.find_elements(By.CLASS_NAME, value=\"_tyxjp1\")\n",
    "    for elem in prix_search :\n",
    "        if elem.text != '' :\n",
    "            features_dict['price'].append(elem.text)\n",
    "            \n",
    "\n",
    "    # Garde of the ad\n",
    "    grade_search = driver.find_elements(By.CLASS_NAME, value=\"_17p6nbba\")\n",
    "    for elem in grade_search :\n",
    "        features_dict['grade'].append(elem.text[0:4])\n",
    "\n",
    "    # Superhost or not ?\n",
    "    try:\n",
    "        superhost = driver.find_element(By.CLASS_NAME, value=\"_1mhorg9\")\n",
    "        features_dict['superhost'].append(superhost.text)\n",
    "    except:\n",
    "        features_dict['superhost'].append('NC')\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Number of comments\n",
    "    commentaires_search = driver.find_elements(By.CLASS_NAME, value=\"_1qx9l5ba\")\n",
    "    for elem in commentaires_search : \n",
    "        if elem.text != '' :\n",
    "            features_dict['nb_comments'].append(elem.text)\n",
    "\n",
    "            \n",
    "            \n",
    "    # Looking for the following elements in a <li> tag \n",
    "    li_search = driver.find_elements(By.TAG_NAME, value=\"li\")\n",
    "    \n",
    "    # Number of travelers\n",
    "    features_dict['nb_travelers'].append(li_search[0].text[0:2])\n",
    "    \n",
    "    # Number of bedrooms\n",
    "    if 'St' in li_search[1].text[2:5] : \n",
    "        features_dict['nb_bedrooms'].append('0')\n",
    "    else : features_dict['nb_bedrooms'].append(li_search[1].text[2:5])\n",
    "    \n",
    "    # Number of beds\n",
    "    features_dict['nb_beds'].append(li_search[2].text[2:5])\n",
    "    \n",
    "    # Number of bathrooms \n",
    "    bathroom = li_search[3].text[2:5]\n",
    "    features_dict['nb_bath'].append(bathroom)\n",
    "\n",
    "    \n",
    "    # We use a regex to get the name of the city\n",
    "    city_search = driver.find_elements(By.CLASS_NAME, value=\"_9xiloll\")\n",
    "    for elem in city_search :\n",
    "        city = elem.text\n",
    "        regex = '^[^,]*'\n",
    "        answ = re.search(regex,city)\n",
    "        features_dict['city'].append(answ.group(0))\n",
    "        \n",
    "\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # We look for the button \"Display the n equipment\" and we click on it\n",
    "    a = driver.find_elements(By.TAG_NAME, value='button')\n",
    "    for elem in a :\n",
    "        # Adapt the string to the language of the airbnb site you are using\n",
    "        if 'équipements' in elem.text :\n",
    "            elem.click()\n",
    "            break\n",
    "\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Looking for the equipment \n",
    "    equipements4 = driver.find_elements(By.CLASS_NAME, value=\"_11jhslp\")\n",
    "    equipements5 = driver.find_elements(By.CLASS_NAME,value='_gw4xx4')\n",
    "    liste = []\n",
    "    \n",
    "    for e in equipements5 :\n",
    "        liste.append(e.text)\n",
    "     \n",
    "    # This loop allows you to search in the list of all the equipment present on the ad.\n",
    "    # If it finds items from the equipment list created earlier in the code, it keeps them.\n",
    "    # If it finds other equipment, it does not take them into account at all.\n",
    "    # Finally, if certain equipment from the equipment list is not mentioned in the ad, it writes NC.\n",
    "    # And this, even if they are unavailable (crossed out on the ad).\n",
    "    \n",
    "    for e in equipment : \n",
    "        if e in liste :\n",
    "            for k in liste :\n",
    "                if e in k : \n",
    "                    if 'Indisponible' in k :\n",
    "                                    if e in features_dict.keys():\n",
    "                                        features_dict[e].append('NC')\n",
    "                                    else : pass\n",
    "                    else : \n",
    "                        if e in features_dict.keys():\n",
    "                            features_dict[e].append(e)\n",
    "                        else : pass\n",
    "        if e not in liste :\n",
    "                features_dict[e].append('NC')\n",
    "    \n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "print(features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2fb592",
   "metadata": {},
   "source": [
    "<br/>\n",
    "To transform the dictionary into a dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36380689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(features_dict, orient='index')\n",
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ead4f1",
   "metadata": {},
   "source": [
    "<br/>\n",
    "To display all rows and columns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7716d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a3663",
   "metadata": {},
   "source": [
    "<br/>\n",
    "After 50 announcements or if the algorithm has stopped on the way, it is necessary to store the first complete lines and without error in a dataframe by removing empty or erroneous lines (which arrive at the end).\n",
    "<br/>\n",
    "Let the features_dict dictionary reset itself. If we let the add continue the dictionary, we will not have to remove empty or erroneous lines from the dictionary, which is a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc370501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example : \n",
    "df1 = df.drop(df.index[50:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4928cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe5fec2",
   "metadata": {},
   "source": [
    "<br/>\n",
    "If you need to concat dataframes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c081f48",
   "metadata": {},
   "source": [
    "<br/>\n",
    "To export your dataframe : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4afe5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Scrap1.csv',sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
